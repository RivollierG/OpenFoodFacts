{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "   tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# for loading/processing the images  \n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = r\"/home/kevin.bouchaud@Digital-Grenoble.local/code/Data_For_Good/images\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path)\n",
    "\n",
    "# this list holds all the image filename\n",
    "images = [i for i in os.listdir(path) if i.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = VGG16()\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\n",
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224, 224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img)\n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1, 224, 224, 3)\n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32960/32960 [29:28<00:00, 18.64it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "pickle_path = r\"/home/kevin.bouchaud@Digital-Grenoble.local/code/Data_For_Good/OpenFoodFacts/features.pkl\"\n",
    "\n",
    "# # lop through each image in the dataset\n",
    "# for image in images:\n",
    "#     # try to extract the features and update the dictionary\n",
    "#     try:\n",
    "#         feat = extract_features(image, model)\n",
    "#         data[image] = feat\n",
    "#     # if something fails, save the extracted features as a pickle file (optional)\n",
    "#     except:\n",
    "#         with open(p,'wb') as file:\n",
    "#             pickle.dump(data, file)\n",
    "\n",
    "for image in tqdm(images):\n",
    "    feat = extract_features(image, model)\n",
    "    data[image] = feat\n",
    "\n",
    "with open(pickle_path, 'wb') as file:\n",
    "    pickle.dump(data, file)\n",
    "\n",
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))\n",
    "\n",
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "\n",
    "# reshape so that there are 210 samples of 4096 vectors\n",
    "feat = feat.reshape(-1, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the unique labels (from the flower_labels.csv)\n",
    "# df = pd.read_csv('flower_labels.csv')\n",
    "# label = df['label'].tolist()\n",
    "# unique_labels = list(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32960it [00:00, 794557.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# reduce the amount of dimensions in the feature vector\n",
    "pca = PCA(n_components=100, random_state=42)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)\n",
    "\n",
    "pickle_reduced_path = r\"/home/kevin.bouchaud@Digital-Grenoble.local/code/Data_For_Good/OpenFoodFacts/reduced_features.pkl\"\n",
    "\n",
    "data_reduced = {}\n",
    "for i, image in enumerate(images):\n",
    "    data_reduced[image] = x[i]\n",
    "\n",
    "with open(pickle_reduced_path, 'wb') as file:\n",
    "    pickle.dump(data_reduced, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32960, 4096)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32960, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # cluster feature vectors\n",
    "# kmeans = KMeans(n_clusters=len(unique_labels),n_jobs=-1, random_state=22)\n",
    "# kmeans.fit(x)\n",
    "\n",
    "# # holds the cluster id and the images { id: [images] }\n",
    "# groups = {}\n",
    "# for file, cluster in zip(filenames,kmeans.labels_):\n",
    "#     if cluster not in groups.keys():\n",
    "#         groups[cluster] = []\n",
    "#         groups[cluster].append(file)\n",
    "#     else:\n",
    "#         groups[cluster].append(file)\n",
    "\n",
    "# # function that lets you view a cluster (based on identifier)        \n",
    "# def view_cluster(cluster):\n",
    "#     plt.figure(figsize = (25,25));\n",
    "#     # gets the list of filenames for a cluster\n",
    "#     files = groups[cluster]\n",
    "#     # only allow up to 30 images to be shown at a time\n",
    "#     if len(files) > 30:\n",
    "#         print(f\"Clipping cluster size from {len(files)} to 30\")\n",
    "#         files = files[:29]\n",
    "#     # plot each image in the cluster\n",
    "#     for index, file in enumerate(files):\n",
    "#         plt.subplot(10,10,index+1);\n",
    "#         img = load_img(file)\n",
    "#         img = np.array(img)\n",
    "#         plt.imshow(img)\n",
    "#         plt.axis('off')\n",
    "        \n",
    "   \n",
    "# # this is just incase you want to see which value for k might be the best \n",
    "# sse = []\n",
    "# list_k = list(range(3, 50))\n",
    "\n",
    "# for k in list_k:\n",
    "#     km = KMeans(n_clusters=k, random_state=22, n_jobs=-1)\n",
    "#     km.fit(x)\n",
    "    \n",
    "#     sse.append(km.inertia_)\n",
    "\n",
    "# # Plot sse against k\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.plot(list_k, sse)\n",
    "# plt.xlabel(r'Number of clusters *k*')\n",
    "# plt.ylabel('Sum of squared distance');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('keras_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "981af5b755b41a09f9e927e4036afd339133834f62b29c8b9be40df6a3c1e0fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
